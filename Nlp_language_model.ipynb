{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IjUWMxqNMyON"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.reset_accumulated_memory_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u81CM4_IMyOO",
        "outputId": "e1bbc5fe-b303-415d-b5e5-173dc8651f55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\abdob\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\abdob\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\abdob\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\abdob\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-N20L9LIMyOO"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and special characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    tokens = word_tokenize(text)  # Tokenize the text\n",
        "    return ' '.join(tokens)  # Join words back into a single string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBXteOpqMyOO",
        "outputId": "f20f3883-b393-4e92-b903-ea08c13ca2d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Line ID Speaker ID Movie ID Character Name          Text processed_text\n",
            "0   L1045         u0       m0         BIANCA  They do not!    they do not\n",
            "1   L1044         u2       m0        CAMERON   They do to!     they do to\n",
            "2    L985         u0       m0         BIANCA    I hope so.      i hope so\n",
            "3    L984         u2       m0        CAMERON     She okay?       she okay\n",
            "4    L925         u0       m0         BIANCA     Let's go.        lets go\n",
            "Line ID            0\n",
            "Speaker ID        69\n",
            "Movie ID          69\n",
            "Character Name    69\n",
            "Text              69\n",
            "processed_text     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "columns = [\"Line ID\", \"Speaker ID\", \"Movie ID\", \"Character Name\", \"Text\"]\n",
        "\n",
        "# Read the file and process lines into a DataFrame\n",
        "with open(\"movie_lines.txt\", 'r', encoding='latin-1') as file:\n",
        "    movie_lines_c = [\n",
        "        line.split(' +++$+++ ') for line in file.read().splitlines() if line.strip()\n",
        "    ]\n",
        "# filtering out empty lines (if line.strip()), which reduces the chance of unexpected errors from blank lines.\n",
        "\n",
        "# Create the DataFrame and drop unnecessary columns\n",
        "movie_lines = pd.DataFrame(movie_lines_c, columns=columns)\n",
        "movie_lines['processed_text']=movie_lines['Text'].apply(lambda x: preprocess_text(str(x)))\n",
        "# Display a sample for verification\n",
        "print(movie_lines.head())\n",
        "print(movie_lines.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pRp8cvkMyOO",
        "outputId": "463871d6-6749-467e-98ad-54566eda4f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Line ID           0\n",
            "Speaker ID        0\n",
            "Movie ID          0\n",
            "Character Name    0\n",
            "Text              0\n",
            "processed_text    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "movie_lines.dropna(inplace=True)\n",
        "print(movie_lines.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "9CmzB3xBMyOO",
        "outputId": "770f299d-a67c-4fed-e55b-3860b258348d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                               they do not\n",
              "1                                                they do to\n",
              "2                                                 i hope so\n",
              "3                                                  she okay\n",
              "4                                                   lets go\n",
              "                                ...                        \n",
              "304777    lord chelmsford seems to want me to stay back ...\n",
              "304778    im to take the sikali with the main column to ...\n",
              "304779                               your orders mr vereker\n",
              "304780    good ones yes mr vereker gentlemen who can rid...\n",
              "304781    colonel durnford william vereker i hear you ve...\n",
              "Name: processed_text, Length: 304713, dtype: object"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movie_lines['processed_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dzjt1MH7MyOP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Check for CUDA availability and set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "movie_lines=movie_lines.sample(frac =.10)\n",
        "# Flatten the processed dialogues into a list of sentences\n",
        "sentences = movie_lines['processed_text'].tolist()\n",
        "\n",
        "# Tokenize and create a vocabulary (token-to-index mapping)\n",
        "tokenizer = nltk.tokenize.word_tokenize\n",
        "all_words = []\n",
        "for sentence in sentences:\n",
        "    all_words.extend(tokenizer(sentence.lower()))\n",
        "\n",
        "# Create a vocabulary\n",
        "vocab = sorted(set(all_words))\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "# Convert sentences to sequences of indices\n",
        "sequences = []\n",
        "for sentence in sentences:\n",
        "    tokenized = tokenizer(sentence.lower())\n",
        "    sequence = [word_to_idx[word] for word in tokenized if word in word_to_idx]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "# Create input-output pairs for training (X: input sequence, Y: next word)\n",
        "sequence_length = 4  # We will use the previous 3 words to predict the next word\n",
        "X_data = []\n",
        "y_data = []\n",
        "for seq in sequences:\n",
        "    for i in range(len(seq) - sequence_length):\n",
        "        X_data.append(seq[i:i + sequence_length])\n",
        "        y_data.append(seq[i + sequence_length])\n",
        "\n",
        "X_data = np.array(X_data)\n",
        "y_data = np.array(y_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1QWMPX6uMyOP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert to PyTorch tensors and move them to CUDA\n",
        "X_data = torch.tensor(X_data, dtype=torch.long).to(device)\n",
        "y_data = torch.tensor(y_data, dtype=torch.long).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx4cyRgqMyOP"
      },
      "source": [
        "# **RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KrdY4k0fMyOP"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RNN_Language_Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
        "        super(RNN_Language_Model, self).__init__()\n",
        "\n",
        "        # Embedding layer to map token indices to GloVe embeddings\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # RNN layer\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Fully connected layer to predict the next word\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get embeddings for the input tokens\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Pass through the RNN\n",
        "        rnn_out, _ = self.rnn(x)\n",
        "\n",
        "        # Use the output of the last time step (we're doing a sequence-to-one task)\n",
        "        out = self.fc(rnn_out[:, -1, :])\n",
        "\n",
        "        return out\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 100  # Using GloVe 100-dimensional vectors\n",
        "hidden_dim = 128  # Hidden layer dimension\n",
        "vocab_size = len(vocab)  # Size of the vocabulary\n",
        "output_size = vocab_size  # Output size is the size of the vocabulary (for next word prediction)\n",
        "\n",
        "# Instantiate the model and move it to CUDA\n",
        "Rnn_model = RNN_Language_Model(vocab_size, embedding_dim, hidden_dim, output_size).to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(Rnn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Create a DataLoader for batching\n",
        "train_dataset = TensorDataset(X_data, y_data)\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR-Tk9xPMyOP"
      },
      "source": [
        "# Training RNN (Skip to load models if you want to test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDEDIsrJMyOP",
        "outputId": "53dee53e-e244-495d-af5e-989011a8b3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 6.823441997351727\n",
            "Epoch [2/100], Loss: 6.054068527082457\n",
            "Epoch [3/100], Loss: 5.757985485151156\n",
            "Epoch [4/100], Loss: 5.52889604522074\n",
            "Epoch [5/100], Loss: 5.3305794258767385\n",
            "Epoch [6/100], Loss: 5.151155008886852\n",
            "Epoch [7/100], Loss: 4.984238798600914\n",
            "Epoch [8/100], Loss: 4.828195547535472\n",
            "Epoch [9/100], Loss: 4.678806004443018\n",
            "Epoch [10/100], Loss: 4.542465238965631\n",
            "Epoch [11/100], Loss: 4.415323822457715\n",
            "Epoch [12/100], Loss: 4.295245250646215\n",
            "Epoch [13/100], Loss: 4.184222373359105\n",
            "Epoch [14/100], Loss: 4.0775206628507075\n",
            "Epoch [15/100], Loss: 3.9761316521034336\n",
            "Epoch [16/100], Loss: 3.8812913755430793\n",
            "Epoch [17/100], Loss: 3.7901107690630167\n",
            "Epoch [18/100], Loss: 3.705016172715347\n",
            "Epoch [19/100], Loss: 3.622527702591425\n",
            "Epoch [20/100], Loss: 3.5447393902316873\n",
            "Epoch [21/100], Loss: 3.4702983917691124\n",
            "Epoch [22/100], Loss: 3.3983372719618528\n",
            "Epoch [23/100], Loss: 3.3310231129908505\n",
            "Epoch [24/100], Loss: 3.266016656754951\n",
            "Epoch [25/100], Loss: 3.204941131192692\n",
            "Epoch [26/100], Loss: 3.145530049238182\n",
            "Epoch [27/100], Loss: 3.0887719082426273\n",
            "Epoch [28/100], Loss: 3.0354756079160965\n",
            "Epoch [29/100], Loss: 2.983809058683632\n",
            "Epoch [30/100], Loss: 2.9337233748749223\n",
            "Epoch [31/100], Loss: 2.8877533439302097\n",
            "Epoch [32/100], Loss: 2.8426445452836306\n",
            "Epoch [33/100], Loss: 2.79879838532775\n",
            "Epoch [34/100], Loss: 2.7578271108242136\n",
            "Epoch [35/100], Loss: 2.719477739937404\n",
            "Epoch [36/100], Loss: 2.6823092568529785\n",
            "Epoch [37/100], Loss: 2.645401153541249\n",
            "Epoch [38/100], Loss: 2.6125171805240233\n",
            "Epoch [39/100], Loss: 2.5792489394074227\n",
            "Epoch [40/100], Loss: 2.547531520073141\n",
            "Epoch [41/100], Loss: 2.517206690317233\n",
            "Epoch [42/100], Loss: 2.487364789285219\n",
            "Epoch [43/100], Loss: 2.4603656771119202\n",
            "Epoch [44/100], Loss: 2.4324516026062977\n",
            "Epoch [45/100], Loss: 2.4084102666581053\n",
            "Epoch [46/100], Loss: 2.383606478535636\n",
            "Epoch [47/100], Loss: 2.3599226457359146\n",
            "Epoch [48/100], Loss: 2.3370014350779735\n",
            "Epoch [49/100], Loss: 2.315605719884237\n",
            "Epoch [50/100], Loss: 2.293343958773462\n",
            "Epoch [51/100], Loss: 2.273389822375165\n",
            "Epoch [52/100], Loss: 2.2538996232977166\n",
            "Epoch [53/100], Loss: 2.2355664777059623\n",
            "Epoch [54/100], Loss: 2.2160178393923164\n",
            "Epoch [55/100], Loss: 2.2003144153423264\n",
            "Epoch [56/100], Loss: 2.182955353219434\n",
            "Epoch [57/100], Loss: 2.1663950713591564\n",
            "Epoch [58/100], Loss: 2.150039766826769\n",
            "Epoch [59/100], Loss: 2.1346470178478825\n",
            "Epoch [60/100], Loss: 2.1209566636677204\n",
            "Epoch [61/100], Loss: 2.1065125639421227\n",
            "Epoch [62/100], Loss: 2.0917951959183037\n",
            "Epoch [63/100], Loss: 2.078155108031855\n",
            "Epoch [64/100], Loss: 2.0665093729965878\n",
            "Epoch [65/100], Loss: 2.0532037115445103\n",
            "Epoch [66/100], Loss: 2.041781816749387\n",
            "Epoch [67/100], Loss: 2.028789758392204\n",
            "Epoch [68/100], Loss: 2.017480067093007\n",
            "Epoch [69/100], Loss: 2.0058787782696914\n",
            "Epoch [70/100], Loss: 1.995952835048202\n",
            "Epoch [71/100], Loss: 1.9849710148326383\n",
            "Epoch [72/100], Loss: 1.9749135904358541\n",
            "Epoch [73/100], Loss: 1.9650013258277355\n",
            "Epoch [74/100], Loss: 1.9549657109300005\n",
            "Epoch [75/100], Loss: 1.9469379128620863\n",
            "Epoch [76/100], Loss: 1.9366114307784106\n",
            "Epoch [77/100], Loss: 1.9270268649660467\n",
            "Epoch [78/100], Loss: 1.9191868189187526\n",
            "Epoch [79/100], Loss: 1.9113090856231911\n",
            "Epoch [80/100], Loss: 1.9030819774544152\n",
            "Epoch [81/100], Loss: 1.8938815422591793\n",
            "Epoch [82/100], Loss: 1.8855517157092871\n",
            "Epoch [83/100], Loss: 1.8791453365571889\n",
            "Epoch [84/100], Loss: 1.8709890694513809\n",
            "Epoch [85/100], Loss: 1.8645021117806724\n",
            "Epoch [86/100], Loss: 1.8566044850361028\n",
            "Epoch [87/100], Loss: 1.848850952737813\n",
            "Epoch [88/100], Loss: 1.8421596851372082\n",
            "Epoch [89/100], Loss: 1.835824741354244\n",
            "Epoch [90/100], Loss: 1.8294103812707312\n",
            "Epoch [91/100], Loss: 1.822869692405645\n",
            "Epoch [92/100], Loss: 1.8175795594561128\n",
            "Epoch [93/100], Loss: 1.8116358045823964\n",
            "Epoch [94/100], Loss: 1.8051974680591965\n",
            "Epoch [95/100], Loss: 1.7988397570422097\n",
            "Epoch [96/100], Loss: 1.792762939947365\n",
            "Epoch [97/100], Loss: 1.7886449522055559\n",
            "Epoch [98/100], Loss: 1.782398697523595\n",
            "Epoch [99/100], Loss: 1.7773486599144854\n",
            "Epoch [100/100], Loss: 1.7721978040217192\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    Rnn_model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        # Move batches to CUDA\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = Rnn_model(X_batch)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, y_batch)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-kGeOXEMyOP"
      },
      "source": [
        "# **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1NrLPNBOMyOQ"
      },
      "outputs": [],
      "source": [
        "class LSTM_Language_Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
        "        super(LSTM_Language_Model, self).__init__()\n",
        "\n",
        "        # Embedding layer to map token indices to embeddings\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Fully connected layer to predict the next word\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get embeddings for the input tokens\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Pass through the LSTM\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Use the output of the last time step\n",
        "        out = self.fc(lstm_out[:, -1, :])\n",
        "\n",
        "        return out\n",
        "\n",
        "# Instantiate the LSTM model\n",
        "lstm_model = LSTM_Language_Model(vocab_size, embedding_dim, hidden_dim, output_size).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ecj5NHabMyOQ"
      },
      "source": [
        "# Training LSTM (Skip to load models if you want to test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Bm0grp9jMyOQ",
        "outputId": "5607849a-db5a-428d-e8da-9c54160c94e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 6.936704494077214\n",
            "Epoch [2/100], Loss: 6.173497096755499\n",
            "Epoch [3/100], Loss: 5.8945350472944495\n",
            "Epoch [4/100], Loss: 5.6951301741774065\n",
            "Epoch [5/100], Loss: 5.523401037619932\n",
            "Epoch [6/100], Loss: 5.364690924502927\n",
            "Epoch [7/100], Loss: 5.213489062594672\n",
            "Epoch [8/100], Loss: 5.067951236038023\n",
            "Epoch [9/100], Loss: 4.925725925287771\n",
            "Epoch [10/100], Loss: 4.788286377333667\n",
            "Epoch [11/100], Loss: 4.654340253259144\n",
            "Epoch [12/100], Loss: 4.525081947772172\n",
            "Epoch [13/100], Loss: 4.400665670705828\n",
            "Epoch [14/100], Loss: 4.282407865617107\n",
            "Epoch [15/100], Loss: 4.170887894874071\n",
            "Epoch [16/100], Loss: 4.063412028797641\n",
            "Epoch [17/100], Loss: 3.961555724596455\n",
            "Epoch [18/100], Loss: 3.865112796607099\n",
            "Epoch [19/100], Loss: 3.772506737651036\n",
            "Epoch [20/100], Loss: 3.6830970927746627\n",
            "Epoch [21/100], Loss: 3.6001997417487077\n",
            "Epoch [22/100], Loss: 3.517418704183722\n",
            "Epoch [23/100], Loss: 3.4398145640853546\n",
            "Epoch [24/100], Loss: 3.36478088952039\n",
            "Epoch [25/100], Loss: 3.293509612118241\n",
            "Epoch [26/100], Loss: 3.2234818378504175\n",
            "Epoch [27/100], Loss: 3.158119437178266\n",
            "Epoch [28/100], Loss: 3.0945861716630105\n",
            "Epoch [29/100], Loss: 3.033471798954799\n",
            "Epoch [30/100], Loss: 2.9742891301203818\n",
            "Epoch [31/100], Loss: 2.918459609767236\n",
            "Epoch [32/100], Loss: 2.863220697481847\n",
            "Epoch [33/100], Loss: 2.8114103052737938\n",
            "Epoch [34/100], Loss: 2.760253875505025\n",
            "Epoch [35/100], Loss: 2.7122129123576366\n",
            "Epoch [36/100], Loss: 2.6640810380596895\n",
            "Epoch [37/100], Loss: 2.6194419907247353\n",
            "Epoch [38/100], Loss: 2.5752215756697088\n",
            "Epoch [39/100], Loss: 2.532688561437194\n",
            "Epoch [40/100], Loss: 2.4927932398162618\n",
            "Epoch [41/100], Loss: 2.4537579363570017\n",
            "Epoch [42/100], Loss: 2.415924225410406\n",
            "Epoch [43/100], Loss: 2.3795638931348666\n",
            "Epoch [44/100], Loss: 2.3437063618588043\n",
            "Epoch [45/100], Loss: 2.308950027990225\n",
            "Epoch [46/100], Loss: 2.275322848862975\n",
            "Epoch [47/100], Loss: 2.2439479639350353\n",
            "Epoch [48/100], Loss: 2.212069647155539\n",
            "Epoch [49/100], Loss: 2.1819895532009377\n",
            "Epoch [50/100], Loss: 2.152862514022493\n",
            "Epoch [51/100], Loss: 2.125096551113175\n",
            "Epoch [52/100], Loss: 2.097767775656243\n",
            "Epoch [53/100], Loss: 2.070350413774922\n",
            "Epoch [54/100], Loss: 2.045725252506507\n",
            "Epoch [55/100], Loss: 2.0192609152364613\n",
            "Epoch [56/100], Loss: 1.9955562622877803\n",
            "Epoch [57/100], Loss: 1.9718769350771197\n",
            "Epoch [58/100], Loss: 1.9489709475324681\n",
            "Epoch [59/100], Loss: 1.92619824206452\n",
            "Epoch [60/100], Loss: 1.9042118355595572\n",
            "Epoch [61/100], Loss: 1.8832943741132453\n",
            "Epoch [62/100], Loss: 1.8623631618318766\n",
            "Epoch [63/100], Loss: 1.8425151669486015\n",
            "Epoch [64/100], Loss: 1.8226052473351324\n",
            "Epoch [65/100], Loss: 1.8038728837549252\n",
            "Epoch [66/100], Loss: 1.784567117110946\n",
            "Epoch [67/100], Loss: 1.7661551962223656\n",
            "Epoch [68/100], Loss: 1.7491328722079016\n",
            "Epoch [69/100], Loss: 1.7325448206741445\n",
            "Epoch [70/100], Loss: 1.716253751675868\n",
            "Epoch [71/100], Loss: 1.6992639651263717\n",
            "Epoch [72/100], Loss: 1.6831517750329346\n",
            "Epoch [73/100], Loss: 1.6672093131536405\n",
            "Epoch [74/100], Loss: 1.6526644569243827\n",
            "Epoch [75/100], Loss: 1.6366976064487095\n",
            "Epoch [76/100], Loss: 1.6231327544163614\n",
            "Epoch [77/100], Loss: 1.6094057850013974\n",
            "Epoch [78/100], Loss: 1.595087179592346\n",
            "Epoch [79/100], Loss: 1.5817589426272687\n",
            "Epoch [80/100], Loss: 1.5685187743528046\n",
            "Epoch [81/100], Loss: 1.5546724274210686\n",
            "Epoch [82/100], Loss: 1.5425097254941063\n",
            "Epoch [83/100], Loss: 1.529340799417519\n",
            "Epoch [84/100], Loss: 1.5172968287827615\n",
            "Epoch [85/100], Loss: 1.5060086357622542\n",
            "Epoch [86/100], Loss: 1.4941278687358772\n",
            "Epoch [87/100], Loss: 1.4818284180912658\n",
            "Epoch [88/100], Loss: 1.471944809540055\n",
            "Epoch [89/100], Loss: 1.4606759780224803\n",
            "Epoch [90/100], Loss: 1.4494230581896148\n",
            "Epoch [91/100], Loss: 1.4393243047152702\n",
            "Epoch [92/100], Loss: 1.4286666763379916\n",
            "Epoch [93/100], Loss: 1.418223382492715\n",
            "Epoch [94/100], Loss: 1.407748631607297\n",
            "Epoch [95/100], Loss: 1.399017884783501\n",
            "Epoch [96/100], Loss: 1.3902685294186112\n",
            "Epoch [97/100], Loss: 1.3805296119402215\n",
            "Epoch [98/100], Loss: 1.3706769911332142\n",
            "Epoch [99/100], Loss: 1.3617396734636775\n",
            "Epoch [100/100], Loss: 1.3531857189470835\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the LSTM model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    lstm_model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        # Move batches to device\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = lstm_model(X_batch)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, y_batch)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY3go_d_MyOQ"
      },
      "source": [
        "# **LSTM with attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6CrJ5v7UMyOQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LSTM_Attention_Language_Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
        "        super(LSTM_Attention_Language_Model, self).__init__()\n",
        "\n",
        "        # Embedding layer to map token indices to embeddings\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Attention layer\n",
        "        self.attention = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "        # Fully connected layer to predict the next word\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get embeddings for the input tokens\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Pass through the LSTM\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Calculate attention scores and apply attention\n",
        "        attention_scores = torch.tanh(self.attention(lstm_out))  # Shape: (batch_size, seq_length, 1)\n",
        "        attention_weights = torch.softmax(attention_scores, dim=1)  # Normalize across the sequence\n",
        "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)  # Weighted sum of LSTM outputs\n",
        "\n",
        "        # Pass through the fully connected layer\n",
        "        out = self.fc(context_vector)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Instantiate the LSTM with Attention model\n",
        "attention_model = LSTM_Attention_Language_Model(vocab_size, embedding_dim, hidden_dim, output_size).to(device)\n",
        "\n",
        "# Define the loss function and optimizer for the LSTM with Attention model\n",
        "optimizer = torch.optim.Adam(attention_model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Wla3dhMyOQ"
      },
      "source": [
        "# Training LSTM with attention (Skip to load models if you want to test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6ptLcIESMyOQ",
        "outputId": "4a138dd6-99fa-4460-ddf2-2a6dc133202b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 7.092240381124826\n",
            "Epoch [2/100], Loss: 6.535681319642821\n",
            "Epoch [3/100], Loss: 6.18769973211915\n",
            "Epoch [4/100], Loss: 5.939977040256027\n",
            "Epoch [5/100], Loss: 5.745075912661216\n",
            "Epoch [6/100], Loss: 5.575710743303136\n",
            "Epoch [7/100], Loss: 5.419562386190224\n",
            "Epoch [8/100], Loss: 5.273941019155683\n",
            "Epoch [9/100], Loss: 5.1314756156754315\n",
            "Epoch [10/100], Loss: 4.993332444026232\n",
            "Epoch [11/100], Loss: 4.859609408970297\n",
            "Epoch [12/100], Loss: 4.727086298077066\n",
            "Epoch [13/100], Loss: 4.598809710964379\n",
            "Epoch [14/100], Loss: 4.473517100016276\n",
            "Epoch [15/100], Loss: 4.349426546816118\n",
            "Epoch [16/100], Loss: 4.2312031546358355\n",
            "Epoch [17/100], Loss: 4.117983337736478\n",
            "Epoch [18/100], Loss: 4.009963662084872\n",
            "Epoch [19/100], Loss: 3.909590666601548\n",
            "Epoch [20/100], Loss: 3.814821043153749\n",
            "Epoch [21/100], Loss: 3.725282434709461\n",
            "Epoch [22/100], Loss: 3.641453137943054\n",
            "Epoch [23/100], Loss: 3.5613864651561653\n",
            "Epoch [24/100], Loss: 3.4848032687992365\n",
            "Epoch [25/100], Loss: 3.4126677756761983\n",
            "Epoch [26/100], Loss: 3.3437868127567634\n",
            "Epoch [27/100], Loss: 3.2778782160032693\n",
            "Epoch [28/100], Loss: 3.2145058615654345\n",
            "Epoch [29/100], Loss: 3.154473083732772\n",
            "Epoch [30/100], Loss: 3.0956487539620876\n",
            "Epoch [31/100], Loss: 3.039108869223119\n",
            "Epoch [32/100], Loss: 2.986326279141317\n",
            "Epoch [33/100], Loss: 2.934608770402969\n",
            "Epoch [34/100], Loss: 2.8854140260793866\n",
            "Epoch [35/100], Loss: 2.8365202622982126\n",
            "Epoch [36/100], Loss: 2.7914532785578077\n",
            "Epoch [37/100], Loss: 2.745927248557989\n",
            "Epoch [38/100], Loss: 2.7029502304801105\n",
            "Epoch [39/100], Loss: 2.663457242241741\n",
            "Epoch [40/100], Loss: 2.6222880977203666\n",
            "Epoch [41/100], Loss: 2.5825684795704493\n",
            "Epoch [42/100], Loss: 2.5462813748640447\n",
            "Epoch [43/100], Loss: 2.5108338440711773\n",
            "Epoch [44/100], Loss: 2.475136535301116\n",
            "Epoch [45/100], Loss: 2.441637870459081\n",
            "Epoch [46/100], Loss: 2.408346835714187\n",
            "Epoch [47/100], Loss: 2.377805945937071\n",
            "Epoch [48/100], Loss: 2.3466210139058803\n",
            "Epoch [49/100], Loss: 2.3167441662790713\n",
            "Epoch [50/100], Loss: 2.288589256813346\n",
            "Epoch [51/100], Loss: 2.259408609130377\n",
            "Epoch [52/100], Loss: 2.2320951171164967\n",
            "Epoch [53/100], Loss: 2.207372993158308\n",
            "Epoch [54/100], Loss: 2.180326462372086\n",
            "Epoch [55/100], Loss: 2.1562740269078535\n",
            "Epoch [56/100], Loss: 2.1327362669645433\n",
            "Epoch [57/100], Loss: 2.1080447699321736\n",
            "Epoch [58/100], Loss: 2.085799395893032\n",
            "Epoch [59/100], Loss: 2.0633813551742666\n",
            "Epoch [60/100], Loss: 2.042574788532118\n",
            "Epoch [61/100], Loss: 2.022066654660116\n",
            "Epoch [62/100], Loss: 1.999995392314419\n",
            "Epoch [63/100], Loss: 1.9807212384657849\n",
            "Epoch [64/100], Loss: 1.9614626233015038\n",
            "Epoch [65/100], Loss: 1.9428230718394555\n",
            "Epoch [66/100], Loss: 1.9244889383478467\n",
            "Epoch [67/100], Loss: 1.9061207112894731\n",
            "Epoch [68/100], Loss: 1.8887364933960629\n",
            "Epoch [69/100], Loss: 1.8718643313196743\n",
            "Epoch [70/100], Loss: 1.8552182231216245\n",
            "Epoch [71/100], Loss: 1.8392329189899195\n",
            "Epoch [72/100], Loss: 1.8226900733010323\n",
            "Epoch [73/100], Loss: 1.8068130657330628\n",
            "Epoch [74/100], Loss: 1.791493600882463\n",
            "Epoch [75/100], Loss: 1.7755927131703881\n",
            "Epoch [76/100], Loss: 1.7621950264974813\n",
            "Epoch [77/100], Loss: 1.7485223034002486\n",
            "Epoch [78/100], Loss: 1.7344909970197655\n",
            "Epoch [79/100], Loss: 1.7201717955642664\n",
            "Epoch [80/100], Loss: 1.7072654263526563\n",
            "Epoch [81/100], Loss: 1.6932311295882918\n",
            "Epoch [82/100], Loss: 1.6819634312840854\n",
            "Epoch [83/100], Loss: 1.6688969593558578\n",
            "Epoch [84/100], Loss: 1.6566308847018982\n",
            "Epoch [85/100], Loss: 1.6439701547877923\n",
            "Epoch [86/100], Loss: 1.6325206985728875\n",
            "Epoch [87/100], Loss: 1.6220726093816642\n",
            "Epoch [88/100], Loss: 1.6092376337724301\n",
            "Epoch [89/100], Loss: 1.5981215424201205\n",
            "Epoch [90/100], Loss: 1.5884997743179619\n",
            "Epoch [91/100], Loss: 1.5767691358742633\n",
            "Epoch [92/100], Loss: 1.5684162288396608\n",
            "Epoch [93/100], Loss: 1.5567686525864612\n",
            "Epoch [94/100], Loss: 1.5459867454793332\n",
            "Epoch [95/100], Loss: 1.5361924386082484\n",
            "Epoch [96/100], Loss: 1.5264850901281166\n",
            "Epoch [97/100], Loss: 1.5169555488294058\n",
            "Epoch [98/100], Loss: 1.506040690589125\n",
            "Epoch [99/100], Loss: 1.4984388505165305\n",
            "Epoch [100/100], Loss: 1.4886306823025075\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the LSTM with Attention model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    attention_model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        # Move batches to device\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = attention_model(X_batch)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, y_batch)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJo555SgMyOQ"
      },
      "source": [
        "# saving models (if needed after training):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "VlsKJeh9MyOQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.save(Rnn_model.state_dict(), 'rnn_model.pth')\n",
        "\n",
        "torch.save(lstm_model.state_dict(), 'lstm_model.pth')\n",
        "\n",
        "torch.save(attention_model.state_dict(), 'att_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaII-SflMyOQ"
      },
      "source": [
        "# Loading models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6ns-eIbzMyOQ",
        "outputId": "37e5de19-7f35-4769-a496-68b4a0568153"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Rnn_model.load_state_dict(torch.load('rnn_model.pth'))\n",
        "lstm_model.load_state_dict(torch.load('lstm_model.pth'))\n",
        "attention_model.load_state_dict(torch.load('att_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vIE_UniNMyOQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to preprocess the input string\n",
        "def preprocess_input(text, word_to_idx, sequence_length=5):\n",
        "    tokens = nltk.tokenize.word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
        "    sequence = [word_to_idx[word] for word in tokens if word in word_to_idx]\n",
        "\n",
        "    # If the sequence is shorter than the required length, pad it with zeros\n",
        "    if len(sequence) < sequence_length:\n",
        "        sequence = [0] * (sequence_length - len(sequence)) + sequence\n",
        "\n",
        "    # Use only the last 'sequence_length' tokens (to keep the input size fixed)\n",
        "    sequence = sequence[-sequence_length:]\n",
        "\n",
        "    # Convert to tensor and return\n",
        "    return torch.tensor(sequence, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Function to predict the next word\n",
        "def predict_next_word(model, text, word_to_idx, idx_to_word, device, sequence_length=5):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    input_tensor = preprocess_input(text, word_to_idx, sequence_length).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get the output from the model\n",
        "        output = model(input_tensor)\n",
        "\n",
        "        # Get the index of the predicted word (the word with the highest probability)\n",
        "        predicted_idx = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        # Map the index to the word\n",
        "        predicted_word = idx_to_word[predicted_idx]\n",
        "\n",
        "    return predicted_word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "w4ZziIRdMyOQ",
        "outputId": "9ae581f2-22fd-4a98-de70-c654a85989c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Next word prediction (RNN): you\n",
            "Next word prediction (LSTM): trained\n",
            "Next word prediction (LSTM with Attention): you\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example usage:\n",
        "text_input = \"hi how are\"\n",
        "\n",
        "RNN_predicted_word = predict_next_word(Rnn_model, text_input, word_to_idx, idx_to_word, device)\n",
        "print(f\"Next word prediction (RNN): {RNN_predicted_word}\")\n",
        "\n",
        "lstm_predicted_word = predict_next_word(lstm_model, text_input, word_to_idx, idx_to_word, device)\n",
        "print(f\"Next word prediction (LSTM): {lstm_predicted_word}\")\n",
        "\n",
        "\n",
        "attention_predicted_word = predict_next_word(attention_model, text_input, word_to_idx, idx_to_word, device)\n",
        "print(f\"Next word prediction (LSTM with Attention): {attention_predicted_word}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "QQnugW0xMyOQ",
        "outputId": "c496f9c4-8339-4256-aa64-23d5d86b68c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your sentence is: i want to\n",
            "the next predicted word:\n",
            "Next word prediction (RNN): get\n",
            "Next word prediction (LSTM): know\n",
            "Next word prediction (LSTM with Attention): make\n"
          ]
        }
      ],
      "source": [
        "text_input=input(\"enter an incomplete sentence\")\n",
        "print(\"your sentence is:\",text_input)\n",
        "print(\"the next predicted word:\")\n",
        "RNN_predicted_word = predict_next_word(Rnn_model, text_input, word_to_idx, idx_to_word, device)\n",
        "print(f\"Next word prediction (RNN): {RNN_predicted_word}\")\n",
        "\n",
        "lstm_predicted_word = predict_next_word(lstm_model, text_input, word_to_idx, idx_to_word, device)\n",
        "print(f\"Next word prediction (LSTM): {lstm_predicted_word}\")\n",
        "\n",
        "\n",
        "attention_predicted_word = predict_next_word(attention_model, text_input, word_to_idx, idx_to_word, device)\n",
        "print(f\"Next word prediction (LSTM with Attention): {attention_predicted_word}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJXLEeVOMyOQ"
      },
      "source": [
        "# **Conclusion**\n",
        "\n",
        "The three models work well and both LSTM and LSTM with attention work alot better than the RNN but the attention doesnt improve the results in this scope(num of epochs,task,etc...)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
